
==============================================================
  GpuTensor Benchmark: ByteArray vs GPU-Resident Buffers
==============================================================

ByteArray: copies data CPU<->GPU on every operation
GpuTensor: data stays on GPU, copies only at start/end

--- Test 1: Single GEMM Operation ---
(Note: ByteArray times show 0 because pure functions don't GPU sync)

Config          | ByteArray   | GpuTensor   | GPU Time
------------------------------------------------------
256x256         | (no sync)   | 243.725ms  | 243.725ms
512x512         | (no sync)   | 191.976ms  | 191.976ms
1024x1024       | (no sync)   | 125.846ms  | 125.846ms

--- Test 2: Chained GEMM (A*B then result*C) ---

With ByteArray: 4 copies per chain (A,B up; AB down,up; AB*C down)
With GpuTensor: 0 copies per chain (all stays on GPU)

Size            | GpuTensor Chain | Est. Transfer Saved
------------------------------------------------------
256x256         | 316.615ms       | ~0.04ms/iter (4x 0.01ms)
512x512         | 57.9716ms       | ~1.1ms/iter (4x 0.28ms)

--- Test 3: Transfer Overhead (Upload + Download) ---
(Pre-creating data to exclude creation time from measurements)


Size               | Upload     | Download   | Total
------------------------------------------------------
256KB (256x256)    | 0.00637ms  | 0.00750ms  | 0.01387ms
1MB (512x512)      | 0.01766ms  | 0.01795ms  | 0.03562ms
4MB (1024x1024)    | 0.11208ms  | 0.27329ms  | 0.38537ms

==============================================================
Summary: GpuTensor eliminates per-operation copy overhead.
Speedup increases with more chained operations.
==============================================================
