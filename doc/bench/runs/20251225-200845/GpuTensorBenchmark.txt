===== GpuTensorBenchmark =====

==============================================================
  GpuTensor Benchmark: ByteArray vs GPU-Resident Buffers
==============================================================

ByteArray: copies data CPU<->GPU on every operation
GpuTensor: data stays on GPU, copies only at start/end

--- Test 1: Single GEMM Operation ---
(Note: ByteArray times show 0 because pure functions don't GPU sync)

Config          | ByteArray   | GpuTensor   | GPU Time
------------------------------------------------------
256x256         | (no sync)   | 0.44477ms  | 0.44477ms
512x512         | (no sync)   | 0.42694ms  | 0.42694ms
1024x1024       | (no sync)   | 0.83028ms  | 0.83028ms

--- Test 2: Chained GEMM (A*B then result*C) ---

With ByteArray: 4 copies per chain (A,B up; AB down,up; AB*C down)
With GpuTensor: 0 copies per chain (all stays on GPU)

Size            | GpuTensor Chain | Est. Transfer Saved
------------------------------------------------------
256x256         | 0.82844ms       | ~0.04ms/iter (4x 0.01ms)
512x512         | 0.99630ms       | ~1.1ms/iter (4x 0.28ms)

--- Test 3: Transfer Overhead (Upload + Download) ---
(Pre-creating data to exclude creation time from measurements)


Size               | Upload     | Download   | Total
------------------------------------------------------
256KB (256x256)    | 0.00488ms  | 0.00685ms  | 0.01174ms
1MB (512x512)      | 0.02082ms  | 0.02034ms  | 0.04117ms
4MB (1024x1024)    | 0.10719ms  | 0.10669ms  | 0.21388ms

==============================================================
Summary: GpuTensor eliminates per-operation copy overhead.
Speedup increases with more chained operations.
==============================================================

