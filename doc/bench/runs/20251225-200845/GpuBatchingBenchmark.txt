===== GpuBatchingBenchmark =====
=== GPU Batching Benchmark ===

Warming up GPU...

--- Test 1: Multiple iterations (3 ops each) ---
Each iteration does: relu → add → mul

  10 iterations, 10000 elements:
    Unbatched: 12.000000 ms
    Batched:   8.000000 ms
    Speedup:   1.500000x

  50 iterations, 10000 elements:
    Unbatched: 55.000000 ms
    Batched:   26.000000 ms
    Speedup:   2.115385x

  100 iterations, 10000 elements:
    Unbatched: 96.000000 ms
    Batched:   44.000000 ms
    Speedup:   2.181818x

--- Test 2: Long chains (single iteration) ---
Chain of N relu operations

  Chain length 10, 100000 elements:
    Unbatched: 4.000000 ms
    Batched:   3.000000 ms
    Speedup:   1.333333x

  Chain length 50, 100000 elements:
    Unbatched: 21.000000 ms
    Batched:   3.000000 ms
    Speedup:   7.000000x

  Chain length 100, 100000 elements:
    Unbatched: 38.000000 ms
    Batched:   6.000000 ms
    Speedup:   6.333333x

  Chain length 200, 100000 elements:
    Unbatched: 58.000000 ms
    Batched:   20.000000 ms
    Speedup:   2.900000x

=== Benchmark Complete ===

Note: Batching reduces CPU-GPU synchronization overhead.
For small/fast operations, the overhead reduction is significant.
For large/slow operations, the GPU compute time dominates.

