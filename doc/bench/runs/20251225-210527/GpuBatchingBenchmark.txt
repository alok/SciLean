===== GpuBatchingBenchmark =====
=== GPU Batching Benchmark ===

Warming up GPU...

--- Test 1: Multiple iterations (3 ops each) ---
Each iteration does: relu → add → mul

  10 iterations, 10000 elements:
    Unbatched: 13.000000 ms
    Batched:   7.000000 ms
    Speedup:   1.857143x

  50 iterations, 10000 elements:
    Unbatched: 63.000000 ms
    Batched:   20.000000 ms
    Speedup:   3.150000x

  100 iterations, 10000 elements:
    Unbatched: 92.000000 ms
    Batched:   56.000000 ms
    Speedup:   1.642857x

--- Test 2: Long chains (single iteration) ---
Chain of N relu operations

  Chain length 10, 100000 elements:
    Unbatched: 3.000000 ms
    Batched:   1.000000 ms
    Speedup:   3.000000x

  Chain length 50, 100000 elements:
    Unbatched: 19.000000 ms
    Batched:   5.000000 ms
    Speedup:   3.800000x

  Chain length 100, 100000 elements:
    Unbatched: 33.000000 ms
    Batched:   7.000000 ms
    Speedup:   4.714286x

  Chain length 200, 100000 elements:
    Unbatched: 57.000000 ms
    Batched:   20.000000 ms
    Speedup:   2.850000x

=== Benchmark Complete ===

Note: Batching reduces CPU-GPU synchronization overhead.
For small/fast operations, the overhead reduction is significant.
For large/slow operations, the GPU compute time dominates.
