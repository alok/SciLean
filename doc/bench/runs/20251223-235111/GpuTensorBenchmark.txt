
==============================================================
  GpuTensor Benchmark: ByteArray vs GPU-Resident Buffers
==============================================================

ByteArray: copies data CPU<->GPU on every operation
GpuTensor: data stays on GPU, copies only at start/end

--- Test 1: Single GEMM Operation ---
(Note: ByteArray times show 0 because pure functions don't GPU sync)

Config          | ByteArray   | GpuTensor   | GPU Time
------------------------------------------------------
256x256         | (no sync)   | 0.29718ms  | 0.29718ms
512x512         | (no sync)   | 0.30848ms  | 0.30848ms
1024x1024       | (no sync)   | 0.79793ms  | 0.79793ms

--- Test 2: Chained GEMM (A*B then result*C) ---

With ByteArray: 4 copies per chain (A,B up; AB down,up; AB*C down)
With GpuTensor: 0 copies per chain (all stays on GPU)

Size            | GpuTensor Chain | Est. Transfer Saved
------------------------------------------------------
256x256         | 0.40202ms       | ~0.04ms/iter (4x 0.01ms)
512x512         | 0.55973ms       | ~1.1ms/iter (4x 0.28ms)

--- Test 3: Transfer Overhead (Upload + Download) ---
(Pre-creating data to exclude creation time from measurements)


Size               | Upload     | Download   | Total
------------------------------------------------------
256KB (256x256)    | 0.00566ms  | 0.00666ms  | 0.01233ms
1MB (512x512)      | 0.01820ms  | 0.01908ms  | 0.03729ms
4MB (1024x1024)    | 0.08320ms  | 0.07504ms  | 0.15824ms

==============================================================
Summary: GpuTensor eliminates per-operation copy overhead.
Speedup increases with more chained operations.
==============================================================
