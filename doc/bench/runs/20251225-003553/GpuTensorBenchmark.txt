
==============================================================
  GpuTensor Benchmark: ByteArray vs GPU-Resident Buffers
==============================================================

ByteArray: copies data CPU<->GPU on every operation
GpuTensor: data stays on GPU, copies only at start/end

--- Test 1: Single GEMM Operation ---
(Note: ByteArray times show 0 because pure functions don't GPU sync)

Config          | ByteArray   | GpuTensor   | GPU Time
------------------------------------------------------
256x256         | (no sync)   | 0.42895ms  | 0.42895ms
512x512         | (no sync)   | 0.38384ms  | 0.38384ms
1024x1024       | (no sync)   | 0.68237ms  | 0.68237ms

--- Test 2: Chained GEMM (A*B then result*C) ---

With ByteArray: 4 copies per chain (A,B up; AB down,up; AB*C down)
With GpuTensor: 0 copies per chain (all stays on GPU)

Size            | GpuTensor Chain | Est. Transfer Saved
------------------------------------------------------
256x256         | 0.51778ms       | ~0.04ms/iter (4x 0.01ms)
512x512         | 0.63216ms       | ~1.1ms/iter (4x 0.28ms)

--- Test 3: Transfer Overhead (Upload + Download) ---
(Pre-creating data to exclude creation time from measurements)


Size               | Upload     | Download   | Total
------------------------------------------------------
256KB (256x256)    | 0.00373ms  | 0.00396ms  | 0.00770ms
1MB (512x512)      | 0.01318ms  | 0.01442ms  | 0.02761ms
4MB (1024x1024)    | 0.06881ms  | 0.06261ms  | 0.13143ms

==============================================================
Summary: GpuTensor eliminates per-operation copy overhead.
Speedup increases with more chained operations.
==============================================================
